type: mlp
model_params:
  hidden_sizes: [100, 100]
  activation: relu
  dropout: 0.0
  batch_norm: false
  bias: true
  init: xavier
  dtype: float32
optimizer_params:
  type: adam
  lr: 0.001
  weight_decay: 0.0
  momentum: 0.0
  alpha: 0.99
  eps: 1e-06
  lr_decay: 0.0
  betas: [0.9, 0.999]

save_model: true
save_dir: saved_models/experts
save_name: mlp
save_period: 10
load_model: false
load_path: saved_models/experts/mlp.pt

# Path: configs\expert_configs\mlp_expert_config.yml
